# ğŸ¤ Audio Streaming Server

Um servidor de streaming de Ã¡udio em tempo real que integra com a API Realtime da OpenAI para transcriÃ§Ã£o e geraÃ§Ã£o de respostas em Ã¡udio e texto.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [Como Usar](#-como-usar)
- [Arquitetura](#-arquitetura)
- [Eventos WebSocket](#-eventos-websocket)
- [API da OpenAI](#-api-da-openai)
- [Desenvolvimento](#-desenvolvimento)
- [Estrutura do Projeto](#-estrutura-do-projeto)

## ğŸ¯ VisÃ£o Geral

Este projeto Ã© um servidor backend que fornece capacidades de streaming de Ã¡udio em tempo real, utilizando WebSockets para comunicaÃ§Ã£o bidirecional com clientes. O servidor atua como um intermediÃ¡rio entre aplicaÃ§Ãµes cliente e a API Realtime da OpenAI, oferecendo:

- âœ¨ **TranscriÃ§Ã£o em tempo real** de Ã¡udio para texto
- ğŸ—£ï¸ **GeraÃ§Ã£o de respostas** em Ã¡udio e texto
- ğŸ”„ **Streaming bidirecional** de dados de Ã¡udio
- ğŸŒ **Interface WebSocket** para comunicaÃ§Ã£o em tempo real
- ğŸ¤– **IntegraÃ§Ã£o completa** com OpenAI Realtime API

## ğŸ› ï¸ Tecnologias Utilizadas

- **Node.js** - Runtime JavaScript
- **TypeScript** - Linguagem principal
- **Fastify** - Framework web rÃ¡pido e eficiente
- **Socket.io** - Biblioteca para WebSockets
- **WebSocket (ws)** - Cliente WebSocket para comunicaÃ§Ã£o com OpenAI
- **Biome** - Linter e formatador de cÃ³digo

## ğŸ“‹ PrÃ©-requisitos

- Node.js (versÃ£o 18 ou superior)
- Chave de API da OpenAI com acesso Ã  Realtime API
- npm ou yarn

## ğŸš€ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <url-do-repositorio>
cd audio-streaming-server
```

2. **Instale as dependÃªncias:**
```bash
npm install
```

3. **Configure as variÃ¡veis de ambiente:**
```bash
cp .env.example .env
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com:

```env
OPENAI_API_KEY=sua_chave_da_openai_aqui
```

### ConfiguraÃ§Ã£o do CORS

Por padrÃ£o, o servidor aceita conexÃµes de `http://localhost:5173`. Para modificar, edite o arquivo `src/server.ts`:

```typescript
cors: {
  origin: 'http://seu-frontend-url.com',
}
```

## ğŸ® Como Usar

### Desenvolvimento

```bash
npm run dev
```

### ProduÃ§Ã£o

```bash
npm start
```

O servidor iniciarÃ¡ na porta **3000** por padrÃ£o.

## ğŸ—ï¸ Arquitetura

O projeto segue uma arquitetura modular com separaÃ§Ã£o clara de responsabilidades:

```
Cliente (Frontend) â†â†’ Socket.io â†â†’ AudioStreamingServer â†â†’ OpenAISessionHandler â†â†’ OpenAI Realtime API
```

### Componentes Principais

1. **AudioStreamingServer** (`src/server.ts`)
   - Gerencia conexÃµes WebSocket
   - Configura middleware e CORS
   - Orquestra a comunicaÃ§Ã£o entre cliente e OpenAI

2. **OpenAISessionHandler** (`src/open-ai-session-handler.ts`)
   - Gerencia sessÃµes individuais com a OpenAI
   - Processa eventos de Ã¡udio e texto
   - MantÃ©m estado da conversa

## ğŸ”Œ Eventos WebSocket

### Eventos Ouvidos pelo Servidor

| Evento | DescriÃ§Ã£o | Payload |
|--------|-----------|---------|
| `start` | Inicia uma nova sessÃ£o com OpenAI | - |
| `audio_chunk` | Recebe chunk de Ã¡udio do cliente | `string` (dados de Ã¡udio em base64) |
| `stop` | Para o envio de Ã¡udio e finaliza entrada | - |
| `disconnect` | Cliente desconectado | - |

### Eventos Emitidos pelo Servidor

| Evento | DescriÃ§Ã£o | Payload |
|--------|-----------|---------|
| `backend_ready` | Servidor pronto para receber Ã¡udio | `{ message: string }` |
| `transcription_partial` | TranscriÃ§Ã£o parcial do Ã¡udio enviado | `string` |
| `transcription_final` | TranscriÃ§Ã£o final do Ã¡udio enviado | `string` |
| `response_transcript_partial` | TranscriÃ§Ã£o parcial da resposta da IA | `string` |
| `response_transcript_final` | TranscriÃ§Ã£o final da resposta da IA | `string` |
| `response_text_delta` | Texto parcial da resposta | `string` |
| `response_text_final` | Texto final da resposta | `string` |
| `response_audio` | Ãudio da resposta da IA | `string[]` (chunks de Ã¡udio) |
| `openai_error` | Erro da API OpenAI | `unknown` |

### Fluxo de ComunicaÃ§Ã£o

```mermaid
sequenceDiagram
    participant C as Cliente
    participant S as Servidor
    participant O as OpenAI

    C->>S: connect
    S->>O: estabelece conexÃ£o WebSocket
    O->>S: session.updated
    S->>C: backend_ready

    C->>S: start
    S->>O: session.update (config)
    
    loop Streaming de Ãudio
        C->>S: audio_chunk
        S->>O: input_audio_buffer.append
        O->>S: transcription.delta
        S->>C: transcription_partial
    end

    C->>S: stop
    S->>O: input_audio_buffer.commit
    
    O->>S: response.audio.delta
    S->>C: response_audio
    O->>S: response.text.delta
    S->>C: response_text_delta
```

## ğŸ¤– API da OpenAI

### ConfiguraÃ§Ã£o da SessÃ£o

O servidor configura automaticamente a sessÃ£o da OpenAI com:

- **Modalidades:** Texto e Ã¡udio
- **Idioma:** PortuguÃªs (forÃ§ado nas instruÃ§Ãµes)
- **Voz:** Alloy
- **Formato de entrada:** PCM16
- **Formato de saÃ­da:** G.711 Î¼-law
- **DetecÃ§Ã£o de turnos:** VAD (Voice Activity Detection) do servidor
- **Temperatura:** 0.8
- **Velocidade:** 1.1x

### Eventos Processados da OpenAI

- `session.updated` - SessÃ£o configurada
- `conversation.item.input_audio_transcription.*` - TranscriÃ§Ã£o do Ã¡udio de entrada
- `response.audio_transcript.*` - TranscriÃ§Ã£o do Ã¡udio de resposta
- `response.content_part.*` - ConteÃºdo textual da resposta
- `response.audio.*` - Dados de Ã¡udio da resposta
- `response.done` - Resposta finalizada
- `error` - Erros da API

## ğŸ‘¨â€ğŸ’» Desenvolvimento

### Scripts DisponÃ­veis

- `npm run dev` - Inicia o servidor em modo desenvolvimento com watch
- `npm start` - Inicia o servidor em modo produÃ§Ã£o

### Ferramentas de Desenvolvimento

- **TypeScript** - Tipagem estÃ¡tica
- **Biome** - Linting e formataÃ§Ã£o
- **Node.js experimental features** - Strip types nativo

### Estrutura de CÃ³digo

O cÃ³digo utiliza classes e mÃ©todos bem organizados:

```typescript
// Exemplo de uso dos handlers
class OpenAISessionHandler {
  handleResponseTextDelta(content: string) {
    this.responseText += content
    this.socket.emit('response_text_delta', content)
  }
}
```

## ğŸ“ Estrutura do Projeto

```
audio-streaming-server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.ts                    # Servidor principal
â”‚   â””â”€â”€ open-ai-session-handler.ts   # Handler da sessÃ£o OpenAI
â”œâ”€â”€ biome.jsonc                      # ConfiguraÃ§Ã£o do Biome
â”œâ”€â”€ index.js                         # VersÃ£o legacy (Express)
â”œâ”€â”€ package.json                     # DependÃªncias e scripts
â”œâ”€â”€ tsconfig.json                    # ConfiguraÃ§Ã£o TypeScript
â””â”€â”€ README.md                        # Este arquivo
```

### Principais Arquivos

- **`src/server.ts`** - Ponto de entrada do servidor Fastify
- **`src/open-ai-session-handler.ts`** - LÃ³gica de integraÃ§Ã£o com OpenAI
- **`index.js`** - ImplementaÃ§Ã£o legacy com Express (nÃ£o utilizada)

## ğŸ”§ PersonalizaÃ§Ã£o

### Modificando a ConfiguraÃ§Ã£o da IA

Para alterar o comportamento da IA, edite o mÃ©todo `createSessionConfig()` em `open-ai-session-handler.ts`:

```typescript
{
  instructions: 'Suas instruÃ§Ãµes personalizadas aqui',
  voice: 'nova-voz',
  temperature: 0.7,
  // ... outras configuraÃ§Ãµes
}
```

### Adicionando Novos Eventos

1. Adicione o handler no `eventHandlers` object
2. Implemente o mÃ©todo correspondente
3. Emita eventos para o cliente conforme necessÃ¡rio

## ğŸ“ Logs e Debugging

O servidor produz logs detalhados para debugging:

- ConexÃµes de clientes
- Eventos da OpenAI
- Estado das transcriÃ§Ãµes
- Erros e exceÃ§Ãµes

Todos os logs sÃ£o prefixados com informaÃ§Ãµes contextuais para facilitar o debugging.

---

**Desenvolvido com â¤ï¸ usando Node.js e TypeScript**
